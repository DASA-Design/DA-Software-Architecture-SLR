### ðŸ“„ Document Summary

**Hockney (1995)** introduces the concept of **computational similarity** to compare performance across parallel machines. He uses **speedup surfaces** and **efficiency models** based on *problem size* and  *processor count* , arguing that two systems can be considered similar if they produce the same speedup for the same workload. This is established through empirical modeling and graphical visualization, aiming to normalize performance differences across systems.

---

### ðŸ”— Relation to Numrichâ€™s Work

Hockneyâ€™s *computational similarity* anticipates the core ideas later formalized by **Robert W. Numrich** using  **dimensional analysis** . While Hockney relies on empirical curves and heuristic reasoning, Numrich generalizes this idea using **dimensionless groups (Ï€-groups)** and **computational forces** to create **universal efficiency surfaces** and machine  **equivalence classes** . Numrich formalizes and extends Hockneyâ€™s premise with rigorous mathematical tools from physics, making the comparison of software performance both scalable and theoretically grounded.
